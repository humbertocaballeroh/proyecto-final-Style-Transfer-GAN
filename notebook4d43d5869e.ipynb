{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-24T03:51:23.209483Z","iopub.execute_input":"2023-03-24T03:51:23.209893Z","iopub.status.idle":"2023-03-24T03:51:23.245174Z","shell.execute_reply.started":"2023-03-24T03:51:23.209857Z","shell.execute_reply":"2023-03-24T03:51:23.243919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n# Load compressed models from tensorflow_hub\nos.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:17:42.442939Z","iopub.execute_input":"2023-03-24T04:17:42.443407Z","iopub.status.idle":"2023-03-24T04:17:53.955280Z","shell.execute_reply.started":"2023-03-24T04:17:42.443341Z","shell.execute_reply":"2023-03-24T04:17:53.953477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as display\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (12, 12)\nmpl.rcParams['axes.grid'] = False\n\nimport numpy as np\nimport PIL.Image\nimport time\nimport functools\nimport matplotlib.image as mpimg\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:17:56.122184Z","iopub.execute_input":"2023-03-24T04:17:56.123796Z","iopub.status.idle":"2023-03-24T04:17:56.130164Z","shell.execute_reply.started":"2023-03-24T04:17:56.123746Z","shell.execute_reply":"2023-03-24T04:17:56.128768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tensor_to_image(tensor):\n  tensor = tensor*255\n  tensor = np.array(tensor, dtype=np.uint8)\n  if np.ndim(tensor)>3:\n    assert tensor.shape[0] == 1\n    tensor = tensor[0]\n  return PIL.Image.fromarray(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:17:57.306432Z","iopub.execute_input":"2023-03-24T04:17:57.307254Z","iopub.status.idle":"2023-03-24T04:17:57.313652Z","shell.execute_reply.started":"2023-03-24T04:17:57.307207Z","shell.execute_reply":"2023-03-24T04:17:57.312247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_path = '/kaggle/input/fotoss/gilda.jpg'\nstyle_path =  '/kaggle/input/fotoss/gildaria style.JPG'","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:18:56.056393Z","iopub.execute_input":"2023-03-24T04:18:56.057683Z","iopub.status.idle":"2023-03-24T04:18:56.063073Z","shell.execute_reply.started":"2023-03-24T04:18:56.057596Z","shell.execute_reply":"2023-03-24T04:18:56.061054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_img(path_to_img):\n  max_dim = 512\n  img = tf.io.read_file(path_to_img)\n  img = tf.image.decode_image(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n\n  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n  long_dim = max(shape)\n  scale = max_dim / long_dim\n\n  new_shape = tf.cast(shape * scale, tf.int32)\n\n  img = tf.image.resize(img, new_shape)\n  img = img[tf.newaxis, :]\n  return img","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:18:56.886300Z","iopub.execute_input":"2023-03-24T04:18:56.887370Z","iopub.status.idle":"2023-03-24T04:18:56.894790Z","shell.execute_reply.started":"2023-03-24T04:18:56.887312Z","shell.execute_reply":"2023-03-24T04:18:56.893466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(image, title=None):\n  if len(image.shape) > 3:\n    image = tf.squeeze(image, axis=0)\n\n  plt.imshow(image)\n  if title:\n    plt.title(title)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:18:57.825960Z","iopub.execute_input":"2023-03-24T04:18:57.826383Z","iopub.status.idle":"2023-03-24T04:18:57.832106Z","shell.execute_reply.started":"2023-03-24T04:18:57.826330Z","shell.execute_reply":"2023-03-24T04:18:57.830928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:19:17.605668Z","iopub.execute_input":"2023-03-24T04:19:17.606057Z","iopub.status.idle":"2023-03-24T04:19:18.631624Z","shell.execute_reply.started":"2023-03-24T04:19:17.606023Z","shell.execute_reply":"2023-03-24T04:19:18.630592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nhub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\nstylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:19:53.384286Z","iopub.execute_input":"2023-03-24T04:19:53.384712Z","iopub.status.idle":"2023-03-24T04:20:04.546207Z","shell.execute_reply.started":"2023-03-24T04:19:53.384675Z","shell.execute_reply":"2023-03-24T04:20:04.545056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_path = '/kaggle/input/fotoss/montse.jpg'\nstyle_path =  '/kaggle/input/fotoss/montse style.jpg'\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:22:58.060611Z","iopub.execute_input":"2023-03-24T04:22:58.061021Z","iopub.status.idle":"2023-03-24T04:22:58.702060Z","shell.execute_reply.started":"2023-03-24T04:22:58.060987Z","shell.execute_reply":"2023-03-24T04:22:58.700708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nhub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\nstylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:23:12.659427Z","iopub.execute_input":"2023-03-24T04:23:12.660717Z","iopub.status.idle":"2023-03-24T04:23:17.807697Z","shell.execute_reply.started":"2023-03-24T04:23:12.660656Z","shell.execute_reply":"2023-03-24T04:23:17.806565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_path = '/kaggle/input/fotoss/nay.jpg'\nstyle_path =  '/kaggle/input/fotoss/nay style.jpg'\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:25:16.588909Z","iopub.execute_input":"2023-03-24T04:25:16.589385Z","iopub.status.idle":"2023-03-24T04:25:17.583927Z","shell.execute_reply.started":"2023-03-24T04:25:16.589328Z","shell.execute_reply":"2023-03-24T04:25:17.582420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nhub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\nstylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:25:35.562367Z","iopub.execute_input":"2023-03-24T04:25:35.562791Z","iopub.status.idle":"2023-03-24T04:25:41.018483Z","shell.execute_reply.started":"2023-03-24T04:25:35.562755Z","shell.execute_reply":"2023-03-24T04:25:41.017127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_path = '/kaggle/input/fotoss/rene.jpg'\nstyle_path =  '/kaggle/input/fotoss/rene style.jpg'\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:28:12.455119Z","iopub.execute_input":"2023-03-24T04:28:12.455697Z","iopub.status.idle":"2023-03-24T04:28:13.222362Z","shell.execute_reply.started":"2023-03-24T04:28:12.455654Z","shell.execute_reply":"2023-03-24T04:28:13.221051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nhub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\nstylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:28:24.407100Z","iopub.execute_input":"2023-03-24T04:28:24.407570Z","iopub.status.idle":"2023-03-24T04:28:29.819885Z","shell.execute_reply.started":"2023-03-24T04:28:24.407527Z","shell.execute_reply":"2023-03-24T04:28:29.818525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_path = '/kaggle/input/fotoss/zahid.jpg'\nstyle_path =  '/kaggle/input/fotoss/zahid style.jpg'\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:31:35.597446Z","iopub.execute_input":"2023-03-24T04:31:35.597928Z","iopub.status.idle":"2023-03-24T04:31:36.558569Z","shell.execute_reply.started":"2023-03-24T04:31:35.597891Z","shell.execute_reply":"2023-03-24T04:31:36.556743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nhub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\nstylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T04:31:54.886158Z","iopub.execute_input":"2023-03-24T04:31:54.887319Z","iopub.status.idle":"2023-03-24T04:32:01.022005Z","shell.execute_reply.started":"2023-03-24T04:31:54.887272Z","shell.execute_reply":"2023-03-24T04:32:01.020734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}